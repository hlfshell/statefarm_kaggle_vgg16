{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The game plan\n",
    "\n",
    "1. Load statefarm input as batches\n",
    "1. Load VGG, observe the layers\n",
    "1. Drop layers that do not seem necessary for my purposes\n",
    "1. ~~Drop final convolution layers (what would be finding higher level features)~~\n",
    "1. Save this as a new model\n",
    "1. Evaluate and save the output from this piece-meal VGG. We will be using this pre-computed data to quickly train up a base model\n",
    "1. Create a new model of ~~a few convolutional layers~~, fully connect connected layers w/ dropout and batch normalization, making sure it ends in our 10 categories via softmax\n",
    "    1. ~~Why add convolutional layers? The last convolutional layers in VGG are for high level features for ImageNet, which we don't need. By adding our own, we hope high level features we need develop.~~--\n",
    "    1. Why add batch normalization? It is not used earlier in VGG, but for our section of the model it will help fight overfittign.\n",
    "    1. Why softmax - because it makes a nice even 0->1 score as an output, making it closer to the actual categorical output we desire (one-hot encoding is still likely required.\n",
    "1. Start doing overfitting / underfitting fixes as we see fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR (theano.sandbox.cuda): nvcc compiler not found on $PATH. Check your nvcc installation and try again.\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "\n",
    "from __future__ import division,print_function\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt\n",
    "import utils; reload(utils)\n",
    "from utils import plots, get_batches, plot_confusion_matrix, get_data\n",
    "\n",
    "from numpy.random import random, permutation\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data\n",
    "Please note that the notebook SF_Dir_Organization, which was originally taken from [here](https://gist.github.com/anonymous/ca79fd0cffaa122cbbf5933b5e1a4c69). \n",
    "\n",
    "As I've been working with it prior, I am assuming that the data has already been created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"data/state/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# batch_size - change depending on what you're doing\n",
    "# batch_size = 4\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18183 images belonging to 10 classes.\n",
      "Found 4241 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#idg = ImageDataGenerator class\n",
    "\n",
    "idg = ImageDataGenerator()\n",
    "\n",
    "training_batch = idg.flow_from_directory(\n",
    "    path + \"/train\",\n",
    "    target_size=(224, 224), # Matching VGG's resolution\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "valid_batch = idg.flow_from_directory(\n",
    "    path + \"/valid\",\n",
    "    target_size=(224, 224),\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABRUAAABKCAYAAAAlmLP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2f22dd5210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let's preview some images - only recommend this if batch_size is 4ish\n",
    "imgs, labels = next(training_batch)\n",
    "plots(imgs, titles=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onehot(x):\n",
    "    return np.array(\n",
    "        OneHotEncoder().fit_transform(x.reshape(-1,1)).todense()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_classes = training_batch.classes\n",
    "valid_classes = valid_batch.classes\n",
    "training_labels = onehot(training_batch.classes)\n",
    "valid_labels = onehot(valid_batch.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does the data look like?\n",
    "The data comes in ten categories.\n",
    "* c0: normal driving\n",
    "* c1: texting - right\n",
    "* c2: talking on the phone - right\n",
    "* c3: texting - left\n",
    "* c4: talking on the phone - left\n",
    "* c5: operating the radio\n",
    "* c6: drinking\n",
    "* c7: reaching behind\n",
    "* c8: hair and makeup\n",
    "* c9: talking to passenger\n",
    "Our goal is to get the image to one-hot encoded output for these ten categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading VGG and stripping it down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import vgg16; reload(vgg16)\n",
    "from vgg16 import Vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??Vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 3, 224, 224)   0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_1 (ZeroPadding2D)  (None, 3, 226, 226)   0           lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 64, 224, 224)  1792        zeropadding2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_2 (ZeroPadding2D)  (None, 64, 226, 226)  0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 64, 224, 224)  36928       zeropadding2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 64, 112, 112)  0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_3 (ZeroPadding2D)  (None, 64, 114, 114)  0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 128, 112, 112) 73856       zeropadding2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_4 (ZeroPadding2D)  (None, 128, 114, 114) 0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 128, 112, 112) 147584      zeropadding2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 128, 56, 56)   0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_5 (ZeroPadding2D)  (None, 128, 58, 58)   0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 256, 56, 56)   295168      zeropadding2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_6 (ZeroPadding2D)  (None, 256, 58, 58)   0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 256, 56, 56)   590080      zeropadding2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_7 (ZeroPadding2D)  (None, 256, 58, 58)   0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 256, 56, 56)   590080      zeropadding2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 256, 28, 28)   0           convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_8 (ZeroPadding2D)  (None, 256, 30, 30)   0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 512, 28, 28)   1180160     zeropadding2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_9 (ZeroPadding2D)  (None, 512, 30, 30)   0           convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 512, 28, 28)   2359808     zeropadding2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_10 (ZeroPadding2D) (None, 512, 30, 30)   0           convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 512, 28, 28)   2359808     zeropadding2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 512, 14, 14)   0           convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_11 (ZeroPadding2D) (None, 512, 16, 16)   0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_12 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_13 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 512, 7, 7)     0           convolution2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 25088)         0           maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 4096)          102764544   flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 4096)          0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 4096)          16781312    dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 4096)          0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 1000)          4097000     dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 138357544\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove all layers up to the second to last CNN, so the last 11 layers\n",
    "for i in range(0, 6):\n",
    "    vgg.model.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 3, 224, 224)   0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_1 (ZeroPadding2D)  (None, 3, 226, 226)   0           lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 64, 224, 224)  1792        zeropadding2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_2 (ZeroPadding2D)  (None, 64, 226, 226)  0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 64, 224, 224)  36928       zeropadding2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 64, 112, 112)  0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_3 (ZeroPadding2D)  (None, 64, 114, 114)  0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 128, 112, 112) 73856       zeropadding2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_4 (ZeroPadding2D)  (None, 128, 114, 114) 0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 128, 112, 112) 147584      zeropadding2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 128, 56, 56)   0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_5 (ZeroPadding2D)  (None, 128, 58, 58)   0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 256, 56, 56)   295168      zeropadding2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_6 (ZeroPadding2D)  (None, 256, 58, 58)   0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 256, 56, 56)   590080      zeropadding2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_7 (ZeroPadding2D)  (None, 256, 58, 58)   0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 256, 56, 56)   590080      zeropadding2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 256, 28, 28)   0           convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_8 (ZeroPadding2D)  (None, 256, 30, 30)   0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 512, 28, 28)   1180160     zeropadding2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_9 (ZeroPadding2D)  (None, 512, 30, 30)   0           convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 512, 28, 28)   2359808     zeropadding2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_10 (ZeroPadding2D) (None, 512, 30, 30)   0           convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 512, 28, 28)   2359808     zeropadding2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 512, 14, 14)   0           convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_11 (ZeroPadding2D) (None, 512, 16, 16)   0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_12 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_13 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 512, 7, 7)     0           convolution2d_13[0][0]           \n",
      "====================================================================================================\n",
      "Total params: 14714688\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model w/ the new layers\n",
    "\n",
    "- Make a new model of the ending layers, consisting of fully connected blocks, consisting of:\n",
    "    - A new flatten layer\n",
    "    - A fully connected layer (2x) of 4096 neurons\n",
    "    - dropout inbetween all dense layers\n",
    "    - A final softmax dense layer\n",
    "    \n",
    "    \n",
    "...which didn't work. No matter what I did I was stuck at 10% or below accuracy - no better than guessing.\n",
    "\n",
    "After a lot of reading and searching, I decided to up the amount of FC layers by one with another ReLu activation and drastically lowering the learning rate. That started to show some promise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(512,7,7)))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "flatten_2 (Flatten)              (None, 25088)         0           flatten_input_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 4096)          102764544   flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 4096)          0           dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 4096)          16781312    dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 4096)          0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 4096)          16781312    dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 4096)          0           dense_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 10)            40970       dropout_5[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 136368138\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-calculate VGG outputs given our training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg_output_training = vgg.model.predict_generator(\n",
    "    training_batch,\n",
    "    training_batch.nb_sample\n",
    ")\n",
    "vgg_output_valid = vgg.model.predict_generator(\n",
    "    valid_batch,\n",
    "    valid_batch.nb_sample\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the data using fast.ai's save_array helper function\n",
    "save_array(path + \"vgg_output_training.bc\", vgg_output_training)\n",
    "save_array(path + \"vgg_output_valid.bc\", vgg_output_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the arrays up using the util function to save time\n",
    "vgg_output_training = load_array(path + \"vgg_output_training.bc\")\n",
    "vgg_output_valid = load_array(path + \"vgg_output_valid.bc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18183, 512, 7, 7)\n",
      "(4241, 512, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "print(vgg_output_training.shape)\n",
    "print(vgg_output_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First attempt\n",
    "For our first attempt we'll be just calling `fit_generator` on our new fully connected layer, without presetting the weights to anything special.\n",
    "\n",
    "Note we're using the above pre-calculated outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I set the learning rate here specifically because it took a lot of experimentation to find a decent learning rate. After getting nowhere with two FC ReLus, I upped it to a third and dropped the learning rate significantly to see if I could find any improvement towards a > 10% accuracy. I found .0000001 to work decently well to get out of the 10% hole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = .0000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18183 samples, validate on 4241 samples\n",
      "Epoch 1/10\n",
      "18183/18183 [==============================] - 374s - loss: 6.4022 - acc: 0.1385 - val_loss: 7.0520 - val_acc: 0.1273\n",
      "Epoch 2/10\n",
      "18183/18183 [==============================] - 365s - loss: 3.3892 - acc: 0.3019 - val_loss: 6.1169 - val_acc: 0.1620\n",
      "Epoch 3/10\n",
      "18183/18183 [==============================] - 362s - loss: 2.0927 - acc: 0.4859 - val_loss: 5.5144 - val_acc: 0.1981\n",
      "Epoch 4/10\n",
      "18183/18183 [==============================] - 363s - loss: 1.3554 - acc: 0.6350 - val_loss: 5.1051 - val_acc: 0.2235\n",
      "Epoch 5/10\n",
      "18183/18183 [==============================] - 365s - loss: 0.9300 - acc: 0.7357 - val_loss: 4.8199 - val_acc: 0.2457\n",
      "Epoch 6/10\n",
      "18183/18183 [==============================] - 364s - loss: 0.6726 - acc: 0.8055 - val_loss: 4.6274 - val_acc: 0.2669\n",
      "Epoch 7/10\n",
      "18183/18183 [==============================] - 369s - loss: 0.5077 - acc: 0.8557 - val_loss: 4.4721 - val_acc: 0.2837\n",
      "Epoch 8/10\n",
      "18183/18183 [==============================] - 366s - loss: 0.3957 - acc: 0.8894 - val_loss: 4.3374 - val_acc: 0.2985\n",
      "Epoch 9/10\n",
      "18183/18183 [==============================] - 364s - loss: 0.3145 - acc: 0.9117 - val_loss: 4.2366 - val_acc: 0.3082\n",
      "Epoch 10/10\n",
      "18183/18183 [==============================] - 365s - loss: 0.2536 - acc: 0.9286 - val_loss: 4.1389 - val_acc: 0.3171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f05027d2a50>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    vgg_output_training,\n",
    "    training_labels,\n",
    "    nb_epoch=10,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(vgg_output_valid, valid_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save these weights\n",
    "model.save_weights(path + \"no_dropout_training.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the weights if you're just coming back\n",
    "model.load_weights(path + \"no_dropout_training.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting for sure, which is good considering the sub 10% accuracy hole I was just in! I added in the dropout prior so I could fight overfitting later (not sure ATM how to add in dropout to a model post-initial fitting, should look into that). So for the next step, let's add dropout back in and see if that improves things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# According to model.summary(), our dropout layers are 2, 4, and 6\n",
    "model.layers[2].p = 0.5\n",
    "model.layers[4].p = 0.5\n",
    "model.layers[6].p = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18183 samples, validate on 4241 samples\n",
      "Epoch 1/10\n",
      "18183/18183 [==============================] - 403s - loss: 0.1983 - acc: 0.9453 - val_loss: 4.0116 - val_acc: 0.3299\n",
      "Epoch 2/10\n",
      "18183/18183 [==============================] - 396s - loss: 0.1448 - acc: 0.9611 - val_loss: 3.9567 - val_acc: 0.3386\n",
      "Epoch 3/10\n",
      "18183/18183 [==============================] - 397s - loss: 0.1096 - acc: 0.9715 - val_loss: 3.8779 - val_acc: 0.3490\n",
      "Epoch 4/10\n",
      "18183/18183 [==============================] - 402s - loss: 0.0845 - acc: 0.9804 - val_loss: 3.8257 - val_acc: 0.3542\n",
      "Epoch 5/10\n",
      " 8768/18183 [=============>................] - ETA: 198s - loss: 0.0701 - acc: 0.9841"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b9517df0d7ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg_output_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1104\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[1;32m   1107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[1;32m    822\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    vgg_output_training,\n",
    "    training_labels,\n",
    "    nb_epoch=10,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(vgg_output_valid, valid_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save these weights\n",
    "model.save_weights(path + \"with_dropout.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load these weights\n",
    "model.load_weights(path + \"with_dropout.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So after ten runs with dropout, we increased our overfitting, and only slightly increased validation accuracy - so we are still overfitting. But since we're no longer in that underfitting hole, we have room to breathe to improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data Augmentation\n",
    "\n",
    "Let's try to use data augmentation in order to prevent over-fitting. I want to try this prior to Batch Normalization because VGG normalizes the input by subtracting its mean when pre-processing.\n",
    "\n",
    "The problem with data augmentation is we can't precompute the first few layers now, so we have to rebuild the model, freeze the earlier convolutional layers, and start training.\n",
    "\n",
    "Should we freeze the last few convolutional layers? Keeping the earlier layers makes sense, as that's where edge detectors and the like would be generated. Later layers, with mroe generalized features, might not fit our data set. For now, I'm going to build the model and not allow training on all convolutional layers, but post this I will open up the last few CNN layers in the model to try and retrain those layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_model = Sequential()\n",
    "\n",
    "for layer in vgg.model.layers:\n",
    "    layer.trainable = False\n",
    "    full_model.add(layer)\n",
    "    \n",
    "for layer in model.layers:\n",
    "    full_model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 3, 224, 224)   0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_1 (ZeroPadding2D)  (None, 3, 226, 226)   0           lambda_1[0][0]                   \n",
      "                                                                   lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 64, 224, 224)  0           zeropadding2d_1[0][0]            \n",
      "                                                                   zeropadding2d_1[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_2 (ZeroPadding2D)  (None, 64, 226, 226)  0           convolution2d_1[0][0]            \n",
      "                                                                   convolution2d_1[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 64, 224, 224)  0           zeropadding2d_2[0][0]            \n",
      "                                                                   zeropadding2d_2[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 64, 112, 112)  0           convolution2d_2[0][0]            \n",
      "                                                                   convolution2d_2[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_3 (ZeroPadding2D)  (None, 64, 114, 114)  0           maxpooling2d_1[0][0]             \n",
      "                                                                   maxpooling2d_1[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 128, 112, 112) 0           zeropadding2d_3[0][0]            \n",
      "                                                                   zeropadding2d_3[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_4 (ZeroPadding2D)  (None, 128, 114, 114) 0           convolution2d_3[0][0]            \n",
      "                                                                   convolution2d_3[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 128, 112, 112) 0           zeropadding2d_4[0][0]            \n",
      "                                                                   zeropadding2d_4[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 128, 56, 56)   0           convolution2d_4[0][0]            \n",
      "                                                                   convolution2d_4[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_5 (ZeroPadding2D)  (None, 128, 58, 58)   0           maxpooling2d_2[0][0]             \n",
      "                                                                   maxpooling2d_2[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 256, 56, 56)   0           zeropadding2d_5[0][0]            \n",
      "                                                                   zeropadding2d_5[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_6 (ZeroPadding2D)  (None, 256, 58, 58)   0           convolution2d_5[0][0]            \n",
      "                                                                   convolution2d_5[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 256, 56, 56)   0           zeropadding2d_6[0][0]            \n",
      "                                                                   zeropadding2d_6[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_7 (ZeroPadding2D)  (None, 256, 58, 58)   0           convolution2d_6[0][0]            \n",
      "                                                                   convolution2d_6[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 256, 56, 56)   0           zeropadding2d_7[0][0]            \n",
      "                                                                   zeropadding2d_7[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 256, 28, 28)   0           convolution2d_7[0][0]            \n",
      "                                                                   convolution2d_7[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_8 (ZeroPadding2D)  (None, 256, 30, 30)   0           maxpooling2d_3[0][0]             \n",
      "                                                                   maxpooling2d_3[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 512, 28, 28)   0           zeropadding2d_8[0][0]            \n",
      "                                                                   zeropadding2d_8[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_9 (ZeroPadding2D)  (None, 512, 30, 30)   0           convolution2d_8[0][0]            \n",
      "                                                                   convolution2d_8[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 512, 28, 28)   0           zeropadding2d_9[0][0]            \n",
      "                                                                   zeropadding2d_9[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_10 (ZeroPadding2D) (None, 512, 30, 30)   0           convolution2d_9[0][0]            \n",
      "                                                                   convolution2d_9[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 512, 28, 28)   0           zeropadding2d_10[0][0]           \n",
      "                                                                   zeropadding2d_10[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 512, 14, 14)   0           convolution2d_10[0][0]           \n",
      "                                                                   convolution2d_10[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_11 (ZeroPadding2D) (None, 512, 16, 16)   0           maxpooling2d_4[0][0]             \n",
      "                                                                   maxpooling2d_4[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 512, 14, 14)   0           zeropadding2d_11[0][0]           \n",
      "                                                                   zeropadding2d_11[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_12 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_11[0][0]           \n",
      "                                                                   convolution2d_11[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 512, 14, 14)   0           zeropadding2d_12[0][0]           \n",
      "                                                                   zeropadding2d_12[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_13 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_12[0][0]           \n",
      "                                                                   convolution2d_12[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D) (None, 512, 14, 14)   0           zeropadding2d_13[0][0]           \n",
      "                                                                   zeropadding2d_13[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 512, 7, 7)     0           convolution2d_13[0][0]           \n",
      "                                                                   convolution2d_13[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 25088)         0           flatten_input_1[0][0]            \n",
      "                                                                   maxpooling2d_5[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 4096)          102764544   flatten_2[0][0]                  \n",
      "                                                                   flatten_2[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 4096)          0           dense_4[0][0]                    \n",
      "                                                                   dense_4[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 4096)          16781312    dropout_3[0][0]                  \n",
      "                                                                   dropout_3[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 4096)          0           dense_5[0][0]                    \n",
      "                                                                   dense_5[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 4096)          16781312    dropout_4[0][0]                  \n",
      "                                                                   dropout_4[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 4096)          0           dense_6[0][0]                    \n",
      "                                                                   dense_6[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 10)            40970       dropout_5[0][0]                  \n",
      "                                                                   dropout_5[1][0]                  \n",
      "====================================================================================================\n",
      "Total params: 136368138\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18183 images belonging to 10 classes.\n",
      "Found 4241 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#idg = ImageDataGenerator class\n",
    "\n",
    "idg = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "training_batch = idg.flow_from_directory(\n",
    "    path + \"/train\",\n",
    "    target_size=(224, 224), # Matching VGG's resolution\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "#reload idg simply because we don't want to\n",
    "#modify the validation\n",
    "\n",
    "idg = ImageDataGenerator()\n",
    "\n",
    "valid_batch = idg.flow_from_directory(\n",
    "    path + \"/valid\",\n",
    "    target_size=(224, 224),\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_model.optimizer.lr = 0.0000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 3, 224, 224)   0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_1 (ZeroPadding2D)  (None, 3, 226, 226)   0           lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 64, 224, 224)  0           zeropadding2d_1[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_2 (ZeroPadding2D)  (None, 64, 226, 226)  0           convolution2d_1[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 64, 224, 224)  0           zeropadding2d_2[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 64, 112, 112)  0           convolution2d_2[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_3 (ZeroPadding2D)  (None, 64, 114, 114)  0           maxpooling2d_1[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 128, 112, 112) 0           zeropadding2d_3[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_4 (ZeroPadding2D)  (None, 128, 114, 114) 0           convolution2d_3[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 128, 112, 112) 0           zeropadding2d_4[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 128, 56, 56)   0           convolution2d_4[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_5 (ZeroPadding2D)  (None, 128, 58, 58)   0           maxpooling2d_2[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 256, 56, 56)   0           zeropadding2d_5[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_6 (ZeroPadding2D)  (None, 256, 58, 58)   0           convolution2d_5[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 256, 56, 56)   0           zeropadding2d_6[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_7 (ZeroPadding2D)  (None, 256, 58, 58)   0           convolution2d_6[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 256, 56, 56)   0           zeropadding2d_7[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 256, 28, 28)   0           convolution2d_7[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_8 (ZeroPadding2D)  (None, 256, 30, 30)   0           maxpooling2d_3[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 512, 28, 28)   0           zeropadding2d_8[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_9 (ZeroPadding2D)  (None, 512, 30, 30)   0           convolution2d_8[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 512, 28, 28)   0           zeropadding2d_9[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_10 (ZeroPadding2D) (None, 512, 30, 30)   0           convolution2d_9[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 512, 28, 28)   0           zeropadding2d_10[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 512, 14, 14)   0           convolution2d_10[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_11 (ZeroPadding2D) (None, 512, 16, 16)   0           maxpooling2d_4[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 512, 14, 14)   0           zeropadding2d_11[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_12 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_11[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 512, 14, 14)   0           zeropadding2d_12[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_13 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_12[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D) (None, 512, 14, 14)   0           zeropadding2d_13[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 512, 7, 7)     0           convolution2d_13[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 25088)         0           maxpooling2d_5[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 4096)          102764544   flatten_2[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 4096)          0           dense_4[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 4096)          16781312    dropout_3[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 4096)          0           dense_5[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 4096)          16781312    dropout_4[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 4096)          0           dense_6[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 10)            40970       dropout_5[1][0]                  \n",
      "====================================================================================================\n",
      "Total params: 136368138\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "??keras.backend.function\n",
    "#iterate = keras.backend.function([input_img, keras.backend.learning_phase()], [loss, grads])\n",
    "#https://github.com/fchollet/keras/issues/2417"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "MissingInputError",
     "evalue": "(\"An input of the graph, used to compute DimShuffle{x,x}(keras_learning_phase), was not provided and not given a value.Use the Theano flag exception_verbosity='high',for more information on this error.\", keras_learning_phase)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mMissingInputError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-2c0dd6f34927>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mnb_val_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, **kwargs)\u001b[0m\n\u001b[1;32m    872\u001b[0m                                         \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_q_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m                                         pickle_safe=pickle_safe)\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1343\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdo_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    701\u001b[0m                                              \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                                              \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m                                              **self._function_kwargs)\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, updates, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Invalid argument '%s' passed to K.function\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, updates, **kwargs)\u001b[0m\n\u001b[1;32m    711\u001b[0m                                         \u001b[0mallow_input_downcast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m                                         \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m                                         **kwargs)\n\u001b[0m\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/compile/function.pyc\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[1;32m    318\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                    output_keys=output_keys)\n\u001b[0m\u001b[1;32m    321\u001b[0m     \u001b[0;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;31m# borrowed used defined inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mpfunc\u001b[0;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[1;32m    477\u001b[0m                          \u001b[0maccept_inplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m                          \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m                          output_keys=output_keys)\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36morig_function\u001b[0;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[1;32m   1774\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1776\u001b[0;31m                    \u001b[0moutput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1777\u001b[0m             defaults)\n\u001b[1;32m   1778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, mode, accept_inplace, function_builder, profile, on_unused_input, fgraph, output_keys)\u001b[0m\n\u001b[1;32m   1426\u001b[0m             \u001b[0;31m# OUTPUT VARIABLES)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m             fgraph, additional_outputs = std_fgraph(inputs, outputs,\n\u001b[0;32m-> 1428\u001b[0;31m                                                     accept_inplace)\n\u001b[0m\u001b[1;32m   1429\u001b[0m             \u001b[0mfgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36mstd_fgraph\u001b[0;34m(input_specs, output_specs, accept_inplace)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     fgraph = gof.fg.FunctionGraph(orig_inputs, orig_outputs,\n\u001b[0;32m--> 177\u001b[0;31m                                   update_mapping=update_mapping)\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/gof/fg.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, features, clone, update_mapping)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__import_r__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"init\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/gof/fg.pyc\u001b[0m in \u001b[0;36m__import_r__\u001b[0;34m(self, variable, reason)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;31m# Imports the owners of the variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mowner\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mowner\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mowner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         if (variable.owner is None and\n\u001b[1;32m    362\u001b[0m                 \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConstant\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/gof/fg.pyc\u001b[0m in \u001b[0;36m__import__\u001b[0;34m(self, apply_node, check, reason)\u001b[0m\n\u001b[1;32m    472\u001b[0m                             \u001b[0;34m\"for more information on this error.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m                             % str(node)),\n\u001b[0;32m--> 474\u001b[0;31m                             r)\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMissingInputError\u001b[0m: (\"An input of the graph, used to compute DimShuffle{x,x}(keras_learning_phase), was not provided and not given a value.Use the Theano flag exception_verbosity='high',for more information on this error.\", keras_learning_phase)"
     ]
    }
   ],
   "source": [
    "full_model.fit_generator(\n",
    "    training_batch,\n",
    "    samples_per_epoch=training_batch.nb_sample,\n",
    "    nb_epoch=10,\n",
    "    validation_data=valid_batch,\n",
    "    nb_val_samples=valid_batch.nb_sample\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
